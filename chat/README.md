# Chat

A simple chat app between a browser client and a python server running inference with an LLM.

Client: Javascript (in browser)
Server: Python web socket server, LLM

# Usage

1. Run `./init.sh` to

- Get client dependencies
- Build client
- Build server docker image

2. Run `./run.sh` run the server.

3. Navigate to `http://localhost:8005`.
